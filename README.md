# ğŸ™ï¸ Q&A Chatbot

An interactive chatbot built with **FastAPI** and **Hugging Face Transformers**. It fetches real-time information from **Wikipedia** and generates responses using local language models, creating a smooth, fully offline Q&A experience.

---

## âœ¨ Technologies

- **FastAPI** â€“ high-performance web framework for building APIs  
- **Uvicorn** â€“ lightning-fast ASGI server to run FastAPI  
- **Jinja2** â€“ template engine for rendering dynamic HTML pages  
- **Python Libraries**:  
  - `transformers` â€“ pre-trained language models from Hugging Face  
  - `wikipedia` â€“ fetches dynamic content from Wikipedia  
  - `requests` â€“ useful for API calls (usually comes with Python)

---

## ğŸš€ Features

- ğŸ” Real-time Wikipedia content fetching  
- ğŸ¤– NLP-powered chatbot responses using transformers  
- ğŸŒ FastAPI backend with templated HTML frontend  
- ğŸ’» Fully local deployment â€” *no paid APIs like OpenAI used*

---

## ğŸ“ The Process

I set out to build a chatbot that could answer user queries dynamically using open-source tools and models.  
- **FastAPI** was chosen for its simplicity and speed in building backend APIs.  
- **Jinja2** helped render clean and responsive HTML pages.  
- I integrated **Hugging Face transformers** to power the chatbot's intelligence and conversation flow.  
- To make it more informative, I used the **wikipedia** Python library to fetch real-time information based on the user's query.  
- The biggest challenge was running large NLP models locally without a GPU â€” which results in slower response times, but everything remains free and offline.

---

## ğŸ¥ Preview
[â–¶ï¸ Watch Demo Video](./assets/preview.mp4)
